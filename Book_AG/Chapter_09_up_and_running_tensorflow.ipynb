{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division,print_function,unicode_literals \n",
    "\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "# to make this notebook's output stable across runs \n",
    "def reset_graph(seed=42): \n",
    "    tf.reset_default_graph() \n",
    "    tf.set_random_seed(seed) \n",
    "    np.random.seed(seed) \n",
    "    \n",
    "#to plot pretty figures\n",
    "%matplotlib inline \n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize']=14\n",
    "plt.rcParams['xtick.labelsize']=12\n",
    "plt.rcParams['ytick.labelsize']=12\n",
    "\n",
    "# where to save the figures \n",
    "PROJECT_ROOT_DIR = \".\" \n",
    "CHAPTER_ID = \"tensorflow\" \n",
    "\n",
    "def save_fig(fig_id,tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR,\"images\",CHAPTER_ID,fig_id + \".png\")\n",
    "    print(\"Saving figure\",fig_id) \n",
    "    if tight_layout: \n",
    "        plt.tight_layoutout()\n",
    "    plt.savefig(path,format='png',dpi=300) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and running a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "x = tf.Variable(3,name=\"x\")\n",
    "y = tf.Variable(4,name=\"y\") \n",
    "f = x*x*y+y+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_7:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer) \n",
    "sess.run(y.initializer) \n",
    "result = sess.run(f)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess: \n",
    "    x.initializer.run()\n",
    "    y.initializer.run() \n",
    "    result = f.eval() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer() \n",
    "with tf.Session() as sess: \n",
    "    init.run() \n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2 \n",
    "y = x + 5\n",
    "z = x*3 \n",
    "with tf.Session() as sess: \n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression \n",
    "### Using the Normal Equation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "reset_graph() \n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m,n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m,1)),housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias,dtype=tf.float32,name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1),dtype=tf.float32,name=\"y\")\n",
    "XT = tf.transpose(X) \n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)),XT),y)\n",
    "\n",
    "with tf.Session() as sess: \n",
    "    theta_value = theta.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.7171074e+01],\n",
       "       [ 4.3633682e-01],\n",
       "       [ 9.3871783e-03],\n",
       "       [-1.0717344e-01],\n",
       "       [ 6.4540231e-01],\n",
       "       [-4.1238391e-06],\n",
       "       [-3.7809242e-03],\n",
       "       [-4.2373490e-01],\n",
       "       [-4.3720812e-01]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with pure Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.69419202e+01]\n",
      " [ 4.36693293e-01]\n",
      " [ 9.43577803e-03]\n",
      " [-1.07322041e-01]\n",
      " [ 6.45065694e-01]\n",
      " [-3.97638942e-06]\n",
      " [-3.78654265e-03]\n",
      " [-4.21314378e-01]\n",
      " [-4.34513755e-01]]\n"
     ]
    }
   ],
   "source": [
    "X = housing_data_plus_bias\n",
    "y = housing.target.reshape(-1,1)\n",
    "theta_numpy = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y) \n",
    "\n",
    "print(theta_numpy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with Scikit-Learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.69419202e+01]\n",
      " [ 4.36693293e-01]\n",
      " [ 9.43577803e-03]\n",
      " [-1.07322041e-01]\n",
      " [ 6.45065694e-01]\n",
      " [-3.97638942e-06]\n",
      " [-3.78654265e-03]\n",
      " [-4.21314378e-01]\n",
      " [-4.34513755e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression \n",
    "lin_reg = LinearRegression() \n",
    "lin_reg.fit(housing.data,housing.target.reshape(-1,1)) \n",
    "\n",
    "print(np.r_[lin_reg.intercept_.reshape(-1,1),lin_reg.coef_.T])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Batch Gradient Descent \n",
    "\n",
    "Gradient Descent requires scaling the feature vectors first. We could do this using TF, but lets just use Scikit-Learn for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "scaled_housing_data = scaler.fit_transform(housing.data) \n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m,1)),scaled_housing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.00000000e+00  6.60969987e-17  5.50808322e-18  6.60969987e-17\n",
      " -1.06030602e-16 -1.10161664e-17  3.44255201e-18 -1.07958431e-15\n",
      " -8.52651283e-15]\n",
      "[ 0.38915536  0.36424355  0.5116157  ... -0.06612179 -0.06360587\n",
      "  0.01359031]\n",
      "0.11111111111111005\n",
      "(20640, 9)\n"
     ]
    }
   ],
   "source": [
    "print(scaled_housing_data_plus_bias.mean(axis=0))\n",
    "print(scaled_housing_data_plus_bias.mean(axis=1)) \n",
    "print(scaled_housing_data_plus_bias.mean())\n",
    "print(scaled_housing_data_plus_bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually computing gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 9.161542\n",
      "Epoch 100 MSE = 0.71450055\n",
      "Epoch 200 MSE = 0.56670487\n",
      "Epoch 300 MSE = 0.55557173\n",
      "Epoch 400 MSE = 0.5488112\n",
      "Epoch 500 MSE = 0.5436363\n",
      "Epoch 600 MSE = 0.53962904\n",
      "Epoch 700 MSE = 0.5365092\n",
      "Epoch 800 MSE = 0.53406775\n",
      "Epoch 900 MSE = 0.5321473\n"
     ]
    }
   ],
   "source": [
    "reset_graph() \n",
    "\n",
    "n_epochs = 1000 \n",
    "learning_rate = 0.01 \n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias,dtype=tf.float32,name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1),dtype=tf.float32,name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0,seed=42),name=\"theta\")\n",
    "y_pred = tf.matmul(X,theta,name=\"predictions\") \n",
    "error = y_pred-y\n",
    "mse = tf.reduce_mean(tf.square(error),name=\"mse\") \n",
    "gradients = 2/m * tf.matmul(tf.transpose(X),error) \n",
    "training_op = tf.assign(theta,theta-learning_rate * gradients) \n",
    "\n",
    "init = tf.global_variables_initializer() \n",
    "\n",
    "with tf.Session() as sess: \n",
    "    sess.run(init) \n",
    "    \n",
    "    for epoch in range(n_epochs): \n",
    "        if epoch % 100 ==0: \n",
    "            print(\"Epoch\",epoch,\"MSE =\",mse.eval())\n",
    "        sess.run(training_op) \n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0685523 ],\n",
       "       [ 0.8874027 ],\n",
       "       [ 0.14401656],\n",
       "       [-0.34770885],\n",
       "       [ 0.36178368],\n",
       "       [ 0.00393811],\n",
       "       [-0.04269556],\n",
       "       [-0.66145283],\n",
       "       [-0.6375278 ]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using autodiff \n",
    "Same as above except for the gradients = ... line: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph() \n",
    "\n",
    "n_epochs = 1000 \n",
    "learning_rate = 0.01 \n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias,dtype=tf.float32,name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1),dtype=tf.float32,name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0,seed=42),name=\"theta\")\n",
    "y_pred = tf.matmul(X,theta,name=\"predictions\") \n",
    "error = y_pred-y\n",
    "mse = tf.reduce_mean(tf.square(error),name=\"mse\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'gradients_5/predictions_grad/MatMul_1:0' shape=(9, 1) dtype=float32>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients = tf.gradients(mse,[theta])[0]\n",
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE= 9.161542\n",
      "Epoch 100 MSE= 0.7145004\n",
      "Epoch 200 MSE= 0.56670487\n",
      "Epoch 300 MSE= 0.55557173\n",
      "Epoch 400 MSE= 0.5488112\n",
      "Epoch 500 MSE= 0.5436363\n",
      "Epoch 600 MSE= 0.53962904\n",
      "Epoch 700 MSE= 0.5365092\n",
      "Epoch 800 MSE= 0.53406775\n",
      "Epoch 900 MSE= 0.5321473\n",
      "Best theta:\n",
      "[[ 2.0685525 ]\n",
      " [ 0.8874027 ]\n",
      " [ 0.14401658]\n",
      " [-0.34770882]\n",
      " [ 0.36178368]\n",
      " [ 0.00393811]\n",
      " [-0.04269556]\n",
      " [-0.6614528 ]\n",
      " [-0.6375277 ]]\n"
     ]
    }
   ],
   "source": [
    "training_op = tf.assign(theta,theta-learning_rate * gradients) \n",
    "\n",
    "init = tf.global_variables_initializer() \n",
    "\n",
    "with tf.Session() as sess: \n",
    "    sess.run(init) \n",
    "    \n",
    "    for epoch in range(n_epochs): \n",
    "        if epoch % 100 == 0: \n",
    "            print(\"Epoch\", epoch,\"MSE=\",mse.eval()) \n",
    "        sess.run(training_op) \n",
    "        \n",
    "    best_theta = theta.eval() \n",
    "\n",
    "print(\"Best theta:\") \n",
    "print(best_theta) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a GradientDescentOptimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph() \n",
    "\n",
    "n_epochs = 1000 \n",
    "learning_rate = 0.01 \n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias,dtype=tf.float32,name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1),dtype=tf.float32,name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0,seed=42),name=\"theta\")\n",
    "y_pred = tf.matmul(X,theta,name=\"predictions\") \n",
    "error = y_pred-y\n",
    "mse = tf.reduce_mean(tf.square(error),name=\"mse\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(mse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 9.161542\n",
      "Epoch 100 MSE = 0.7145004\n",
      "Epoch 200 MSE = 0.56670487\n",
      "Epoch 300 MSE = 0.55557173\n",
      "Epoch 400 MSE = 0.5488112\n",
      "Epoch 500 MSE = 0.5436363\n",
      "Epoch 600 MSE = 0.53962904\n",
      "Epoch 700 MSE = 0.5365092\n",
      "Epoch 800 MSE = 0.53406775\n",
      "Epoch 900 MSE = 0.5321473\n",
      "Best theta:\n",
      "[[ 2.0685525 ]\n",
      " [ 0.8874027 ]\n",
      " [ 0.14401658]\n",
      " [-0.34770882]\n",
      " [ 0.36178368]\n",
      " [ 0.00393811]\n",
      " [-0.04269556]\n",
      " [-0.6614528 ]\n",
      " [-0.6375277 ]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer() \n",
    "with tf.Session() as sess: \n",
    "    sess.run(init) \n",
    "    \n",
    "    for epoch in range(n_epochs): \n",
    "        if epoch % 100 ==0: \n",
    "            print(\"Epoch\",epoch,\"MSE =\",mse.eval())\n",
    "        sess.run(training_op) \n",
    "    best_theta = theta.eval() \n",
    "    \n",
    "print(\"Best theta:\") \n",
    "print(best_theta) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding data to the training algorithm\n",
    "\n",
    "### Placeholder nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 7. 8.]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph() \n",
    "\n",
    "A = tf.placeholder(tf.float32,shape=(None,3))\n",
    "B = A + 5\n",
    "\n",
    "with tf.Session() as sess: \n",
    "    B_val_1 = B.eval(feed_dict={A:[[1,2,3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A:[[4,5,6],[7,8,9]]})\n",
    "\n",
    "print(B_val_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9. 10. 11.]\n",
      " [12. 13. 14.]]\n"
     ]
    }
   ],
   "source": [
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-batch Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph() \n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None,n+1),name=\"X\")\n",
    "y = tf.placeholder(tf.float32,shape=(None,1),name=\"y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0,seed=42),name=\"theta\")\n",
    "y_pred = tf.matmul(X,theta,name=\"predictions\")\n",
    "error = y_pred-y\n",
    "mse = tf.reduce_mean(tf.square(error),name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate) \n",
    "training_op = optimizer.minimize(mse) \n",
    "\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100 \n",
    "n_batches = int(np.ceil(m/batch_size)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch(epoch,batch_index,batch_size): \n",
    "    np.random.seed(epoch * n_batches + batch_index) \n",
    "    indices = np.random.randint(m,size = batch_size) \n",
    "    X_batch = scaled_housing_data_plus_bias[indices]\n",
    "    y_batch = housing.target.reshape(-1,1)[indices]\n",
    "    return X_batch,y_batch \n",
    "\n",
    "with tf.Session() as sess: \n",
    "    sess.run(init) \n",
    "    for epoch in range(n_epochs): \n",
    "        for batch_index in range(n_batches): \n",
    "            X_batch,y_batch = fetch_batch(epoch,batch_index,batch_size) \n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch}) \n",
    "    best_theta = theta.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0703337 ],\n",
       "       [ 0.8637145 ],\n",
       "       [ 0.12255151],\n",
       "       [-0.31211874],\n",
       "       [ 0.38510373],\n",
       "       [ 0.00434168],\n",
       "       [-0.01232954],\n",
       "       [-0.83376896],\n",
       "       [-0.8030471 ]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the graph\n",
    "### inside Jupyter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_graph_in_jupyter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-f90d85f98499>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_graph_in_jupyter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_graph_in_jupyter'"
     ]
    }
   ],
   "source": [
    "from tensorflow_graph_in_jupyter import show_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TensorBoard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph() \n",
    "\n",
    "from datetime import datetime \n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\") \n",
    "root_logdir = \"tf_logs\" \n",
    "logdir = \"{}/run-{}/\".format(root_logdir,now) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000 \n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None,n+1),name=\"X\") \n",
    "y = tf.placeholder(tf.float32, shape=(None,1),name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0,seed=42),name=\"theta\")\n",
    "y_pred = tf.matmul(X,theta,name=\"predications\")\n",
    "error = y_pred - y \n",
    "mse = tf.reduce_mean(tf.square(error),name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate) \n",
    "training_op = optimizer.minimize(mse) \n",
    "\n",
    "init = tf.global_variables_initializer() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_summary = tf.summary.scalar('MSE',mse) \n",
    "file_writer = tf.summary.FileWriter(logdir,tf.get_default_graph()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10 \n",
    "batch_size = 100 \n",
    "n_batches = int(np.ceil(m/batch_size)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess: \n",
    "    sess.run(init) \n",
    "    for epoch in range(n_epochs): \n",
    "        for batch_index in range(n_batches): \n",
    "            X_batch,y_batch = fetch_batch(epoch,batch_index,batch_size) \n",
    "            if batch_index%10==0: \n",
    "                summary_str = mse_summary.eval(feed_dict={X:X_batch,y:y_batch})\n",
    "                step = epoch * n_batches + batch_index \n",
    "                file_writer.add_summary(summary_str,step) \n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch})\n",
    "    best_theta = theta.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0703337 ],\n",
       "       [ 0.8637145 ],\n",
       "       [ 0.12255151],\n",
       "       [-0.31211874],\n",
       "       [ 0.38510373],\n",
       "       [ 0.00434168],\n",
       "       [-0.01232954],\n",
       "       [-0.83376896],\n",
       "       [-0.8030471 ]], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name Scopes\n",
    "When dealing with more complex models such as neural networks, the graph can easily become cluttered with thousands of nodes. To avoid this, we can create name scopes to group related nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph() \n",
    "now = datetime.utcnow().strftime('%Y%m%d%H%M%S') \n",
    "root_logdir = \"tf_logs\" \n",
    "logdir = \"{}/run-{}/\".format(root_logdir,now) \n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape = (None,n+1),name=\"X\")\n",
    "y = tf.placeholder(tf.float32,shape = (None,1),name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0,seed=42),name=\"theta\")\n",
    "y_pred = tf.matmul(X,theta,name=\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\") as scope: \n",
    "    error = y_pred-y\n",
    "    mse = tf.reduce_mean(tf.square(error),name=\"mse\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse) \n",
    "\n",
    "init = tf.global_variables_initializer() \n",
    "\n",
    "mse_summary = tf.summary.scalar('MSE',mse) \n",
    "file_writer = tf.summary.FileWriter(logdir,tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Theta:\n",
      "[[ 2.0703337 ]\n",
      " [ 0.8637145 ]\n",
      " [ 0.12255151]\n",
      " [-0.31211874]\n",
      " [ 0.38510373]\n",
      " [ 0.00434168]\n",
      " [-0.01232954]\n",
      " [-0.83376896]\n",
      " [-0.8030471 ]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100 \n",
    "n_batches = int(np.ceil(m/batch_size)) \n",
    "\n",
    "with tf.Session() as sess: \n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch,y_batch = fetch_batch(epoch,batch_index,batch_size)\n",
    "            if batch_index % 10 ==0: \n",
    "                summary_str = mse_summary.eval(feed_dict = {X:X_batch,y:y_batch})\n",
    "                step = epoch * n_batches + batch_index \n",
    "                file_writer.add_summary(summary_str,step) \n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch})\n",
    "    best_theta = theta.eval()\n",
    "\n",
    "file_writer.flush() \n",
    "file_writer.close() \n",
    "print(\"Best Theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/sub\n"
     ]
    }
   ],
   "source": [
    "print(error.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/mse\n"
     ]
    }
   ],
   "source": [
    "print(mse.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
